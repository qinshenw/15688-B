{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial will introduce you the whole process of getting data, reformatting data and mining data. This time, I choose to use data that are scraped from Yelp to complete the whole thing. At Yelp, every business obtains many rankings and reviews from customers. As a rule of thumb, there must be some connections between rankings and reviews. Therefore, natural language processing methods are needed here. In this tutorial, I use TF-IDF technology to predict potential rankings from given reviews for Chinese food restaurants in New York."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial content\n",
    "\n",
    "In this tutorial, I will introduce you how to scrape data by using [YelpAPI](https://github.com/gfairchild/yelpapi) and [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/), how to calculate TF-IDF by using [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) and how to find connections by using [pairwise_distances](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html).\n",
    "\n",
    "We will cover the following topics in this tutorial:\n",
    "- [Installing the libraries](#Installing-the-libraries)\n",
    "- [Scraping data](#Scraping-data)\n",
    "- [Reformatting data](#Reformatting-data)\n",
    "- [Mining data](#Mining-data)\n",
    "- [Testing data](#Testing-data)\n",
    "- [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start, you have to install necessary libraries to support our journey. Fortunately, most of the libraries we need are already installed if you are using anaconda version of python. The only library you need to install manually is [YelpAPI](https://github.com/gfairchild/yelpapi). Install it using `pip`:\n",
    "\n",
    "\n",
    "    $ pip install yelpapi\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yelpapi import YelpAPI\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import heapq \n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To manipulate data, first we need to get the data. Since we want some useful data from Yelp, why not try YelpAPI which is created specially for scraping from Yelp. With YelpAPI, we don't need any front knowledge like HTTP requests. All we need to do is giving API some parameters and then receive what we want! In order to know what parameters there are, see [Parameters](https://www.yelp.com/developers/documentation/v3/business_search)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there is one more preparation we need to do. Notice that Yelp use some authentication to limit our scraper, we have to deliver our identity infomation before establishing connection with Yelp. In this tutorial, I use API Key to authenticate myself. If you don't have one, please visit [Generate API keys](https://www.yelp.com/developers/v3/manage_app) to generate your own API Key. \n",
    "Since API Key is very private. I won't show you my API Key here. Instead, you can input your own API Key for the following parameter `Yelp_KEY` if you want to rerun the code next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yelp_KEY = 'Please enter your API Key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can actually begin to collect our data! Here I want to get the urls of restaurants which have more than 1000 reviews in first 150 Chinese restaurants in New York. The reason why I need these urls will be illustrated next. To do so, just use `search_query` function that YelpAPI provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_api = YelpAPI(Yelp_KEY,timeout_s=1.5)\n",
    "url_list = []\n",
    "for i in range(3):\n",
    "    search_results = yelp_api.search_query(location='NY',categories='chinese',term='Chinese food',limit=50,offset=i*50)\n",
    "    for j in range(50):\n",
    "        if search_results['businesses'][j]['review_count']>=1000:\n",
    "            url_list.append(search_results['businesses'][j]['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `search_query` stores all the 13 urls we want. Let's see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.yelp.com/biz/wah-fung-no-1-new-york-2?adjust_creative=X8ALXV4ZcN7s6s_iugIWbw&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=X8ALXV4ZcN7s6s_iugIWbw',\n",
       " 'https://www.yelp.com/biz/joes-shanghai-new-york-2?adjust_creative=X8ALXV4ZcN7s6s_iugIWbw&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=X8ALXV4ZcN7s6s_iugIWbw',\n",
       " 'https://www.yelp.com/biz/noodle-village-new-york-7?adjust_creative=X8ALXV4ZcN7s6s_iugIWbw&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=X8ALXV4ZcN7s6s_iugIWbw']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(url_list))\n",
    "url_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, YelpAPI can scrape as much business general information as we want, which is delightful. However, things become a little different when scraping reviews. From the [YelpAPI document](https://www.yelp.com/developers/documentation/v3/business_reviews), we are unfortunately informed that we are only able to extract up to 3 reviews for one single restaurant. It is far from enough to build a NLP model. Therefore, we have to use BeautifulSoup to get reviews and rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is why I need urls of these restaurants, as aforementioned. To make a BeautifulSoup, we first need to use [requests](http://docs.python-requests.org/en/master/) to make HTTP requests. These urls I have can help me visit separate restaurants' websites as the parameter of `get` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since one web page only contains 10 reviews, we have to modify our urls. Notice that we can add `start=offset` at the end of url to turn the page. What's more, the default sort method at Yelp tends to show reviews with high rankings, which is contrary to random sampling. Therefore, I add `sort_by=date_desc` at the end of url in order to make the data distribution more reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to scrape 600 pairs of rankings and reviews for each restaurant. Don't forget to wait for a slight moment between two queries in order to avoid getting block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_yelp(url):\n",
    "    ans = []\n",
    "    #10reviews/page,need 600reviews/restaurant\n",
    "    for offset in range(60):\n",
    "        time.sleep(0.2)\n",
    "        response = requests.get(url+'&sort_by=date_desc&start='+str(offset*10))\n",
    "        #replace <br> with space\n",
    "        soup = BeautifulSoup(response.text.replace('<br>',' '), \"html.parser\")\n",
    "        for i in soup.find_all('li','margin-b5__373c0__2ErL8 border-color--default__373c0__3-ifU'):\n",
    "            temp = i.find('div',{'class':re.compile(r'i-stars__373c0__1T6rz i-stars--regular')})\n",
    "            if temp is None:\n",
    "                continue\n",
    "            rank = int(temp.get('aria-label').split(' ')[0])\n",
    "            review = i.find('span',{'class':'raw__373c0__3rcx7'}).text\n",
    "            ans.append((rank,review))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can actually get rankings and reviews from Yelp! Because the whole query is very time-consuming, it took me more than one hours to get all the data. Therefore, for each restaurant's data, I split them into two files for future use. First 80% of data go into `train.txt` and remaining data go into `test.txt`. For each line in files, the first character represents for the ranking and reviews start from the second character to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:590 2:600 3:600 4:600 5:570 6:600 7:600 8:590 9:600 10:600 11:600 12:590 13:570 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = open('train.txt', 'wt', encoding='utf-8')\n",
    "f2 = open('test.txt', 'wt', encoding='utf-8')\n",
    "for i in range(len(url_list)):\n",
    "    data = scrape_yelp(url_list[i])\n",
    "    print(str(i+1)+':'+str(len(data)),end=' ')\n",
    "    for j in data[:int(len(data)*0.8)]:\n",
    "        f1.write(str(j[0])+' '+j[1]+'\\n')\n",
    "    for j in data[int(len(data)*0.8):]:\n",
    "        f2.write(str(j[0])+' '+j[1]+'\\n')\n",
    "f1.close\n",
    "f2.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that even though I make 60 queries for each restaurant, the result I get is not always 600(60 pages and 10 per page). It is because when we make lots of HTTP requests in a short time, inevitably we will face the situation called [packet loss](https://en.wikipedia.org/wiki/Packet_loss). In this situation, one or two or even more requests will lose, depending on your network environment. Fortunately, we have already got enough data to complete next processes. So it is not a big deal here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformatting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the review text we just scraped from Yelp is kind of immature, we have to reformat it to make it appropriate for the following mining. After reading the raw text, I notice that there are lots of escape symbols. For example, in the text we have `Where\\'s`, we should use [regular expression](https://docs.python.org/3/library/re.html) to finish the translation. Full steps are as followed:\n",
    "1. Convert the text to lower case.\n",
    "2. Replace all the `\\'` with `'`.\n",
    "3. Replace all the `'s` with a whitespace.\n",
    "4. Remove all the `'`.\n",
    "5. Replace all the `\\n`,`\\xa0` with a whitespace.\n",
    "6. Replace all the non-alphanumeric characters with a whitespace.\n",
    "7. Shrink continuous whitespaces into single whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r'\\'','\\'',line) #Where\\'s -> Where's\n",
    "    line = re.sub('\\'s',r'',line)  #What's -> What\n",
    "    line = re.sub('\\'',r'',line) #don't -> dont\n",
    "    line = re.sub(r'\\n',r' ',line) \n",
    "    line = re.sub(r'\\xa0',r' ',line)\n",
    "    line = re.sub(r'[^a-zA-Z0-9]',r' ',line)\n",
    "    line = re.sub('[\\s]+',' ',line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have finished `preprocess` function, let's use it to read data from the files we created before. First we read from `train.txt`, store data in list `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = open('train.txt', 'rt', encoding='utf-8')\n",
    "data = []\n",
    "for line in f1:\n",
    "    rank = int(line[0])\n",
    "    review = preprocess(line[2:])\n",
    "    data.append((rank,review))\n",
    "f1.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many data we have for training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6168"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train = len(data)\n",
    "len_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a deep insight into our data, let's plot our data vividly. Here I am curious about how many reviews I have for each ranking(from  1 to 5). We can easily do this by using [matplotlib.pyplot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rank = [0,0,0,0,0]\n",
    "for i in data:\n",
    "    rank[i[0]-1]+=1\n",
    "plt.bar([1,2,3,4,5],rank)\n",
    "plt.title('rank distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the amount of reviews with ranking 5 and 4 is far more than other rankings. It can be easily explained. It is because most of the restaurants we scrape from Yelp have the overall ranking between 4 and 5. If here we have the amount of reviews with ranking 1 to be the biggest one, it means these restaurants are so so terrible. Such a set of terrible restaurants is unlikely to be the subset of first 150 restaurants at Yelp in a big city. Therefore, the biased distribution is totally reasonable and doesn't obey randomness. Good news is that around 500 reviews of each low ranking are definitely enough for our goal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because TF-IDF process needs both training and testing data to be in the matrix, now we read data from `test.txt` and append results into `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = open('test.txt', 'rt', encoding='utf-8')\n",
    "for line in f1:\n",
    "    rank = int(line[0])\n",
    "    review = preprocess(line[2:])\n",
    "    data.append((rank,review))\n",
    "f1.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1526"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_test = len(data)-len_train\n",
    "len_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see we have 1526 new items in `data`, which is the amount of all testing data. Since the amount of training data is 6168, we can know the total amount of data we scrape from Yelp is 1526 + 6168 = 7694."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we come to the last step of reformatting data. First, we need to add all the reviews into `corpus`, which is necessary for the TF-IDF process. Next, we divide all the data into six groups. For data from `test.txt`, we need to divide them into group 0, which means unknown ranking. Of course we know their rankings, but considering we need them to make prediction, let's pretend that we don't know it just for a while. For data from `train.txt`, we divide them into the group with the group id same to their rankings. Grouped results are stored in dict `rank_group`. There are six keys in `rank_group` and each value stores the list of all the group members' indices in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "rank_group = {0:[],1:[],2:[],3:[],4:[],5:[]}\n",
    "for i in range(len_train):\n",
    "    corpus.append(data[i][1])\n",
    "    rank_group[data[i][0]].append(i)\n",
    "for i in range(len_train,len(data)):\n",
    "    corpus.append(data[i][1])\n",
    "    rank_group[0].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now we have finished all the data preprocessing work, next we can actually mine our data and find some amazing connections among data. Since we have many long texts of reviews and each review has it own ranking, intuitively we can feel that there must be some connection between reviews and rankings. Because reviews contain so many words, a proper [NLP technology](https://en.wikipedia.org/wiki/Natural_language_processing) is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will use [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) as the way to mine our data. In a word, TF-IDF is term frequency times inverse document frequency. You can find the formula in [this link](https://en.wikipedia.org/wiki/Tf%E2%80%93idf). It represents the importance of a word in our texts. However, this time we won't calculate TF-IDF manually. With the help of [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html), TF-IDF can be quickly acquired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we build our own `TfidfVectorizer`, we need to know a new concept of [stop word](https://en.wikipedia.org/wiki/Stop_word). In our text, there are many too common words, like `is`,`we` and `the`. They contribute nothing to our model and may become noises. These words are called stop words. We can use [nltk.corpus](https://www.nltk.org/api/nltk.corpus.html) to get stopwords set. However, such stopwords set is not installed initially in our laptop. You have to manually download `stopwords.zip` from [here](https://github.com/nltk/nltk_data/tree/gh-pages/packages/corpora) and unzip it to the path `Anaconda\\nltk_data\\corpora`. After doing so, we can import `stopwords` conveniently from `nltk.corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build our `TfidfVectorizer`. There are so many [parameters](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) we can deliver to customize our TfidfVectorizer. Here I use `max_df`, `min_df` and `stop_words` to minimize noises in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7694, 4371)\n"
     ]
    }
   ],
   "source": [
    "vectorize = TfidfVectorizer(max_df=0.4, min_df=5, stop_words=stop_words)\n",
    "tfidf_matrix = vectorize.fit_transform(corpus)\n",
    "print(tfidf_matrix.shape)\n",
    "all_words = vectorize.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that our `tfidf_matrix` contains 7694 rows, which is the same as our `data` length and 4371 columns, which is the amount of different useful words in our `corpus`. We can get these words by using `get_feature_names` function and store them into `all_words`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have built a `tfidf_matrix`, let's see what we can directly get from it. Because tf-idf represents the importance of words, I'd like to see what most important words are in different groups. Just add different rows in same group and use [heapq](https://docs.python.org/3/library/heapq.html) to sort the result. Common sort can only give us values, but using heapq we can get indices, which is useful to locate data from `all_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: us never rude bad waiter asked worst terrible horrible said ever disappointed taste know experience tip table take give could customer told went half coming disgusting minutes quality going bao tasted wont used staff another say made delivery star want money gave took times reviews sorry bland leave attitude extremely \n",
      "2: taste disappointed wasnt way bland mediocre salty bao us bad okay reviews took table ok many disappointing quality tasted dumpling used hot hype went experience take average nothing wont since however made sure prices dan price say skin never two cheap gave asked years else cold thing understand could authentic \n",
      "3: taste okay ok wasnt dan bad though overall however bit nothing us still table way think average decent maybe salty shrimp stars take nice went could lot bland probably roast dumpling broth price sure around hot give bao special tasty prices small used line felt know quality find youre places \n",
      "4: dan bit cash tasty nice roast authentic shrimp spot cheap still small quick flavorful hot table price worth lunch take line fast dumpling super big though hand around shanghai overall meal lot congee pulled wonton favorite scallion fresh fish youre pan since taste everything right first wasnt broth night sure \n",
      "5: dan favorite worth everything nyc ever fresh line super new roast fast price spot authentic small highly cheap flavorful must nice quick hot excellent cant tasty make cash perfect dumpling every city shanghai friendly shrimp staff york meal tried tofu loved around lunch coming style first went pulled broth bao \n"
     ]
    }
   ],
   "source": [
    "tfidf_array = tfidf_matrix.toarray()\n",
    "for i in range(1,6):\n",
    "    print(str(i)+':',end=' ')\n",
    "    common = [0]*len(all_words)\n",
    "    for j in rank_group[i]:\n",
    "        common = [common[k]+tfidf_array[j][k] for k in range(len(all_words))]\n",
    "    index_list = map(common.index, heapq.nlargest(50, common))\n",
    "    for j in index_list:\n",
    "        print(all_words[j],end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output, we have 50 most important words for each group. Let's just focus on adjectives and see what we can find.\n",
    "1. rude, bad, worst, terrible, horrible, disappointed, disgusting, bland\n",
    "2. disappointed, bland, mediocre, salty, bad, disappointing\n",
    "3. okay, ok, bad, salty, nice, bland, special\n",
    "4. nice, flavorful, worth, favorite, fresh, right\n",
    "5. favorite, worth, fresh, flavorful, nice, excellent, perfect, friendly, loved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the above list is just like a ranking for adjectives describing from worst to best. For reviews with ranking 1, adjectives are terrible and horrible, while for reviews with ranking 5, words change to excellent and perfect. Therefore, we can know there are really some connections between reviews and rankings, and our `TfidfVectorizer` does work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to quantify such connections, we will use [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)(PCC) here. It can measure the linear correlation between data. Its formula is very similar to the way we calculate [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity). To help with your comprehension, you can just regard it as a normalized version of cosine similarity. All the values are between -1 and 1. Closer to 1 the absolute value is, stronger the relation between two data. Fortunately, we don't bother to calculate PCC manually. We only need to use [pairwise_distances](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html) function from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.04094508, 0.23812962, ..., 0.11391017, 0.02348288,\n",
       "        0.01930431],\n",
       "       [0.04094508, 1.        , 0.07597318, ..., 0.        , 0.02844406,\n",
       "        0.03532278],\n",
       "       [0.23812962, 0.07597318, 1.        , ..., 0.01407753, 0.10587301,\n",
       "        0.02310784],\n",
       "       ...,\n",
       "       [0.11391017, 0.        , 0.01407753, ..., 1.        , 0.01692119,\n",
       "        0.        ],\n",
       "       [0.02348288, 0.02844406, 0.10587301, ..., 0.01692119, 1.        ,\n",
       "        0.03310031],\n",
       "       [0.01930431, 0.03532278, 0.02310784, ..., 0.        , 0.03310031,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson = 1-pairwise_distances(tfidf_matrix, metric=\"cosine\")\n",
    "pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can predict rankings for the reviews in `test.txt`! What we need to do is to calculate the mean pearson correlation coefficient of each ranking group for every ungrouped review. The ranking group that has biggest PCC is the final group we predict the review should be in. Since we have the actual ranking of testing reviews, we can compare the actual value with predicted value to judge how well our work is. \n",
    "\n",
    "Notice that `test_result` function has a parameter `thre`. It allows us to change the precision of the results. If `shre` is 0, it means the predicted value can be regarded as the right answer only when it is exactly the same as actual value. If `shre` is 1, it means if actual value is 5, both 4 and 5 can be regarded as the right answer. The reason why I set parameter `shre` will be illustrated further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result(thre):\n",
    "    right = 0\n",
    "    wrong = 0\n",
    "    for i in rank_group[0]:\n",
    "        x = [0,0,0,0,0]\n",
    "        for j in range(5):\n",
    "            for k in rank_group[j+1]:\n",
    "                x[j]+=pearson[i][k]\n",
    "        x[0]/=len(rank_group[1])\n",
    "        x[1]/=len(rank_group[2])\n",
    "        x[2]/=len(rank_group[3])\n",
    "        x[3]/=len(rank_group[4])\n",
    "        x[4]/=len(rank_group[5])\n",
    "        predict = x.index(max(x))+1\n",
    "        if(abs(predict-data[i][0])<=thre):\n",
    "            right+=1\n",
    "        else:\n",
    "            wrong+=1\n",
    "    print('right:'+str(right))\n",
    "    print('wrong:'+str(wrong))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's set `shre` = 0 and see what the result is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right:784\n",
      "wrong:742\n"
     ]
    }
   ],
   "source": [
    "test_result(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the result seems not good here, even though the correct percent is beyond 50%. Notice it is not a two-category problem. We have 5 categories, so such a correct percent is totally acceptable. \n",
    "\n",
    "However, it is always good to find out why the result is not perfect. Let's try to set `shre` = 1 and see how the result changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right:1406\n",
      "wrong:120\n"
     ]
    }
   ],
   "source": [
    "test_result(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! The result changes so dramatically. And now it seems definitely good for me. But why can changing `shre` generate two different results?\n",
    "\n",
    "Let's go back to the list of most important adjective words for each group we concluded before. For your convenience, I will paste it here again.\n",
    "1. rude, bad, worst, terrible, horrible, disappointed, disgusting, bland\n",
    "2. disappointed, bland, mediocre, salty, bad, disappointing\n",
    "3. okay, ok, bad, salty, nice, bland, special\n",
    "4. nice, flavorful, worth, favorite, fresh, right\n",
    "5. favorite, worth, fresh, flavorful, nice, excellent, perfect, friendly, loved\n",
    "\n",
    "As we can see, there is actually no explicit dividing line between two adjacent ranking groups. For example, group 1 and 2 have overlapping words `disappointed`, `bad`, `bland`, as well as group 4 and 5 have overlapping words `nice`, `flavorful`, `favorite`, etc. This can explain why the result is not that good when `shre` = 0. From the perspective of individual words, the adjacent two groups are too similar. TF-IDF technology can not tell which one of two groups is the right answer. That also explains why our result is close to 50%, because now the problem degenerates into something like 2-category problem.\n",
    "\n",
    "However, things change when `shre` = 1. This time we don't force TF-IDF to give us one exact group id. Just find out the adjacent group is ok. Now we get a very reasonable result. The similarity of two adjacent groups is far bigger than nonadjacent groups. Therefore, the expected result is more accurate. Let's try `shre` = 2 and see if the result could be more perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right:1491\n",
      "wrong:35\n"
     ]
    }
   ],
   "source": [
    "test_result(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, the result now becomes more satisfactory. However, for a problem with 5 categories, setting `shre` as 2 seems too merciful. Just set `shre` as 1 and we can get our final reasonable result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial introduces the whole process from getting data to verifying the work. Together we successfully accomplished the task of predicting review's ranking by using `TF-IDF`. As we mentioned, the reviews are too subjective, it is possible that somebody says \"I like the food very much!\" and then gives ranking 4 instead of 5. In addtion, TF-IDF only focuses on individual word itself, neglecting semantic aspects. Thus, TF-IDF can not give the exact accurate predicted rankings. Maybe you can try other NLP methods, such as [n-gram](https://en.wikipedia.org/wiki/N-gram) and [word2vec](https://en.wikipedia.org/wiki/Word2vec), to deal with the problem. However, if you just consider there are three groups: `excellent`, `so-so` and `horrible`, TF-IDF here will give you perfect answer as you expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
